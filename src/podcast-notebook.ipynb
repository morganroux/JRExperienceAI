{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from agent import CAMELAgent, get_sys_msgs\n",
    "form src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_version = \"gpt-3.5-turbo\" #gpt-4\n",
    "interviewer = \"Joe Roegan\"\n",
    "interviewee = \"Sam Altman\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interviewer_sys_msg, interviewee_sys_msg = get_sys_msgs(\n",
    "    interviewer, interviewee\n",
    ")\n",
    "interviewer_agent = CAMELAgent(interviewer_sys_msg, ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=model_version, temperature=0.2, model_kwargs={\"frequency_penalty\":0}))\n",
    "interviewee_agent = CAMELAgent(interviewee_sys_msg, ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=model_version, temperature=0.2, model_kwargs={\"frequency_penalty\":0}))\n",
    "\n",
    "interviewer_agent.reset()\n",
    "interviewee_agent.reset()\n",
    "\n",
    "conversation=[]\n",
    "interviewee_msg = \"\"\n",
    "interviewer_msg = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation loop : run to generate a Q&A step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "step_msg = interviewer_agent.step(interviewee_msg)\n",
    "interviewer_msg = HumanMessage(content=step_msg.content)\n",
    "transcript = f\"{interviewer}:\\n\\n{interviewer_msg.content}\\n\\n\"\n",
    "print(transcript)\n",
    "conversation.append(transcript)\n",
    "\n",
    "\n",
    "step_msg = interviewee_agent.step(interviewer_msg)\n",
    "interviewee_msg = HumanMessage(content=step_msg.content)\n",
    "transcript = f\"{interviewee}:\\n\\n{interviewee_msg.content}\\n\\n\"\n",
    "print(transcript)\n",
    "conversation.append(transcript)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Director : here you can add directives to Joe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directive = \"you are going very angry if I'm calling you Jay again. You're name is Joe. You're proud of your name.\"\n",
    "\n",
    "interviewer_agent.add_directives(directive)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Director : here you can add directives to the interviewee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directive = \"Stop calling him Jay, call him Joe now\"\n",
    "\n",
    "interviewee_agent.add_directives(directive)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug : check the messages of each participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Joe internal messages:\")\n",
    "for r in interviewer_agent.build_complete_message_list():\n",
    "    print(f\"===={r.type.capitalize()}:\\n\", r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"interviewee internal messages:\")\n",
    "for r in interviewee_agent.build_complete_message_list():\n",
    "    print(f\"===={r.type.capitalize()}:\\n\", r.content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the full conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('conversation.txt', 'w') as f:\n",
    "    for line in conversation:\n",
    "      f.write(line)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it more conversational\n",
    "(split the converation by using `conversation[n:m]` syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=model_version, temperature=0, model_kwargs={\"frequency_penalty\":0})\n",
    "prompt = \"============\\n\"\n",
    "for line in conversation[0:5]:\n",
    "    prompt += line\n",
    "prompt += \"===========\\n\"\n",
    "prompt += \"\"\"\n",
    "From the transcript above, enhance the conversation by making it more conversational : add some \"hum\", \"yeah\" and very little words as if the people were reacting quickly to each other, as if they were really talking.\n",
    "\n",
    "for example :\n",
    "BEFORE:\n",
    "\"Joe Roegan:\n",
    "Sam. Everything's going good on my end, man. Just living the dream, you know? So, let's dive right into it. You've had quite the journey in the tech world, from starting your own company to leading Y Combinator. Can you tell us a bit about your background and how you got into the tech industry?\"\n",
    "\n",
    "AFTER :\n",
    "\"Joe Roegan:\n",
    "Sam. Everything's going good on my end, man. Just living the dream, you know?\n",
    "\n",
    "Sam Altman: yeah\n",
    "\n",
    "Joe Roegan:\n",
    "So, let's dive right into it. You've had quite the journey in the tech world, from starting your own company to leading Y Combinator.\n",
    "\n",
    "Sam Altman: Mmh mmh\n",
    "\n",
    "Joe Roegan: Can you tell us a bit about your background and how you got into the tech industry?\n",
    "\"\"\"\n",
    "\n",
    "new_conv = chat_llm([SystemMessage(content=prompt)])\n",
    "print(new_conv.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
